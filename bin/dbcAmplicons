#!/usr/bin/env python

# dbcAmplicons
#
######################################################################
#
# dbcAmplicons is an application which processes raw four read
# (2 sequence reads and 2 barcode reads) Illumina amplicon experiments.
#
######################################################################

import sys
import os
import argparse
from subprocess import Popen
from subprocess import PIPE
from subprocess import STDOUT
from subprocess import check_call
from subprocess import CalledProcessError
from multiprocessing import cpu_count

from distutils import spawn

profile = False

# version 0.3.0
# initial release add support for preprocess and splitreads
# version 0.4.0
# add support for multiple input files
# version 0.5.0
# reconfigure repository and interface
# version 0.5.1
# added support for rdp classification
# version 0.5.2
# rdp classification and abundance table generation available
# version 0.5.3
# added support for project with no primers
# version 0.5.4
# added convert2ReadTo4Read.py script in scripts folder, minor edits to main dbcAmplicons application
# version 0.5.5
# added support for gzip in a separate process and ability to infer read file names
# version 0.5.6
# added support for Fluidgm down stream processing of samples, in scripts/R
# version 0.5.7
# increased speed in gzip read, and bug fixes
# version 0.5.8
# fixed bug in barcodes mismatches, added two new flags to preprocess keep primer and test
# version 0.5.9
# added script to split by sample, appending output files through iterations
# version 0.6.0
# added support for output of biom format in abundance tables
# version 0.6.1
# added validate app, some pep modification and various tweeks
# version 0.6.2
# bugfixes and cleanup, merge customRDP, scripts, mapping with develop, close issue #1, varius bug fixes
# version 0.6.3
# addressed issue #11, validate pairs in primer file
# version 0.6.4
# modified abundance output, flash output and reporting, fix issue #12
# version 0.6.5
# Show error message and download for RDP when not found

version_num = "v0.6.5-05152015"


#####################################################################################
# Validate the sample, barcode and primer files
def validateParser(subparsers):
    """
    validateParser parser parameters
    """
    #
    # Parse options
    #
    validate_parser = subparsers.add_parser('validate', help='validate the sample, barcode and primer sheets')
    validate_parser.add_argument('-B', '--barcodes_file', help='file with barcodes',
                        action='store', type=str, dest='barcodes_file', metavar='FILENAME', required=True)
    validate_parser.add_argument('-P', '--primer_file', help='file with primers',
                        action='store', type=str, dest='primer_file', metavar='FILENAME', required=True)
    validate_parser.add_argument('-S', '--sample_metadata', help='file with sample metadata',
                        action='store', type=str, dest='samples_file', metavar='FILENAME', required=True)
    validate_parser.add_argument('-v', '--silent', help='silences verbose output [default: %(default)s]',
                        action='store_true', dest='verbose', default=False)
    validate_parser.add_argument('--debug', help='show traceback on error',
                        action='store_true', dest="debug", default=False)
    return validate_parser


class validateCMD:
    """
    validate validateApp parser parameters and launch the app
    """
    def __init__(self):
        pass

    def execute(self, args):
        verbose = not args.verbose
        # ----------------------- options input files -----------------------
        bcFile = args.barcodes_file
        sFile = args.samples_file
        prFile = args.primer_file

        from dbcAmplicons import validateApp
        app = validateApp()

        if profile:
            import cProfile
            cProfile.runctx('app.start(bcFile, prFile, sFile, verbose, args.debug)', globals(), locals())
            return 255
        else:
            return app.start(bcFile, prFile, sFile, verbose, args.debug)


#####################################################################################
# Preprocess four read raw amplicon data set
def preprocessParser(subparsers):
    """
    preprocessParser parser parameters
    """
    #
    # Parse options
    #
    preprocess_parser = subparsers.add_parser('preprocess', help='Preprocess four read raw amplicon data, identifying barcode and primer sequence')
    preprocess_parser.add_argument('-B', '--barcodes_file', help='file with barcodes',
                        action='store', type=str, dest='barcodes_file', metavar='FILENAME', required=True)
    preprocess_parser.add_argument('-d', '--barcodediff', help='max hamming dist from barcode [default: %(default)s]',
                        type=int, dest='barcodediff', default=1)
    preprocess_parser.add_argument('-P', '--primer_file', help='file with primers',
                        action='store', type=str, dest='primer_file', metavar='FILENAME', default=None)
    preprocess_parser.add_argument('-D', '--primerdiff', help='max hamming dist from primer [default: %(default)s]',
                        type=int, dest='primerdiff', default=4)
    preprocess_parser.add_argument('-e', '--primerend', help='required number of matching bases at end of primer [default: %(default)s]',
                        type=int, dest='primerend', default=4)
    preprocess_parser.add_argument('-S', '--sample_metadata', help='file with sample metadata',
                        action='store', type=str, dest='samples_file', metavar='FILENAME', default=None)
    preprocess_parser.add_argument('-q', '--minQ', help="trim 3' end of sequences to minQ [default: %(default)s]",
                        type=int, dest='minQ', default=None),
    preprocess_parser.add_argument('-l', '--minL', help='if minQ is not None, only keep reads that are at least minL length [default: %(default)s]',
                        type=int, dest='minL', default=0),
    preprocess_parser.add_argument('-b', '--batchsize', help='batch size to process reads in [default: %(default)s]',
                        type=int, dest='batchsize', default=100000)
    preprocess_parser.add_argument('-O', '--output_prefix', help='output file basename [default: fastq_prefix]',
                        action='store', type=str, dest='output_base', metavar='PREFIX', default=None)
    preprocess_parser.add_argument('-U', '--output_unidentified', help='output unidentified reads [default: %(default)s]',
                        action='store_true', dest='unidentified', default=False)
    preprocess_parser.add_argument('-u', '--uncompressed', help='leave output files uncompressed [default: %(default)s]',
                        action='store_true', dest='uncompressed', default=False)
    preprocess_parser.add_argument('-v', '--silent', help='silences verbose output [default: %(default)s]',
                        action='store_true', dest='verbose', default=False)
    preprocess_parser.add_argument('-1', metavar="read1", dest='fastq_file1', help='read1 of an amplicon fastq four file set',
                        action='store', type=str, required=True, nargs='+')
    preprocess_parser.add_argument('-2', metavar="read2", dest='fastq_file2', help='read2 of an amplicon fastq four file set',
                        action='store', type=str, required=False, nargs='+')
    preprocess_parser.add_argument('-3', metavar="read3", dest='fastq_file3', help='read3 of an amplicon fastq four file set',
                        action='store', type=str, required=False, nargs='+')
    preprocess_parser.add_argument('-4', metavar="read4", dest='fastq_file4', help='read4 of an amplicon fastq four file set',
                        action='store', type=str, required=False, nargs='+')
    preprocess_parser.add_argument('--test', help='exit after the first batch in order to test the inputs',
                        action='store_true', dest="test", default=False)
    preprocess_parser.add_argument('--keepPrimers', help="Don't cut off the primer sequence, leave it as a part of the read [default: %(default)d]",
                        action='store_true', dest="kprimer", default=False)
    preprocess_parser.add_argument('--debug', help='show traceback on error',
                        action='store_true', dest="debug", default=False)
    return preprocess_parser


class preprocessCMD:
    """
    validate preprocessApp parser parameters and launch the app
    """
    def __init__(self):
        pass

    def execute(self, args):
        verbose = not args.verbose
        # ----------------------- options input files -----------------------
        bcFile = args.barcodes_file
        if args.samples_file is None:
            sFile = None
            if verbose:
                sys.stderr.write("No sample file identified\n")
        else:
            sFile = args.samples_file
        if args.primer_file is None:
            prFile = None
            if verbose:
                sys.stderr.write("No primer file identified\n")
        else:
            prFile = args.primer_file
        # ----------------------- options output prefix -----------------------
        if args.output_base is None and sFile is None:
            output_prefix = "preprocessed_out"
        elif args.output_base is None and sFile is not None:
            output_prefix = "."
        elif args.output_base is not None and sFile is None:
            output_prefix = args.output_base
        elif args.output_base is not None and sFile is not None:
            output_prefix = args.output_base

        from dbcAmplicons import preprocessApp
        app = preprocessApp()

        if profile:
            import cProfile
            cProfile.runctx('app.start(args.fastq_file1, args.fastq_file2, args.fastq_file3, args.fastq_file4, output_prefix, bcFile, prFile, sFile, args.barcodediff, args.primerdiff, args.primerend, args.batchsize, args.uncompressed, args.unidentified, args.minQ, args.minL, verbose, args.debug, args.kprimer, args.test)', globals(), locals())
            return 255
        else:
            return app.start(args.fastq_file1, args.fastq_file2, args.fastq_file3, args.fastq_file4, output_prefix, bcFile, prFile, sFile, args.barcodediff, args.primerdiff, args.primerend, args.batchsize, args.uncompressed, args.unidentified, args.minQ, args.minL, verbose, args.debug, args.kprimer, args.test)


#####################################################################################
# Split Preprocessed data by project
def splitreadsParser(subparsers):
    """
    splitreadsParser parser parameters
    """
    #
    # Parse options
    #
    preprocess_parser = subparsers.add_parser('splitreads', help='Split reads from a preprocessed four read illumina run by project id')
    preprocess_parser.add_argument('-b', '--batchsize', help='batch size to process reads in [default: %(default)s]',
                        type=int, dest='batchsize', default=100000)
    preprocess_parser.add_argument('-O', '--output_path', help='path for output files [default: %(default)s]',
                        action='store', type=str, dest='output_base', metavar='PREFIX', default=".")
    preprocess_parser.add_argument('-U', '--output_unidentified', help='output unidentified reads [default: %(default)s]',
                        action='store_true', dest='unidentified', default=False)
    preprocess_parser.add_argument('-u', '--uncompressed', help='leave output files uncompressed [default: %(default)s]',
                        action='store_true', dest='uncompressed', default=False)
    preprocess_parser.add_argument('-v', '--silent', help='verbose output [default: %(default)s]',
                        action='store_true', dest='verbose', default=False)
    preprocess_parser.add_argument('-S', '--sample_metadata', help='file with sample metadata',
                        action='store', type=str, dest='samples_file', metavar='FILENAME', default=None, required=True)
    preprocess_parser.add_argument('-1', metavar="read1", dest='fastq_file1', help='read1 of an amplicon fastq two file set',
                        action='store', type=str, required=True, nargs='+')
    preprocess_parser.add_argument('-2', metavar="read2", dest='fastq_file2', help='read2 of an amplicon fastq two file set',
                        action='store', type=str, required=False, nargs='+')
    preprocess_parser.add_argument('--debug', help='show traceback on error',
                        action='store_true', dest="debug", default=False)
    return preprocess_parser


class splitreadsCMD:
    """
    validate splitreadsApp parser parameters and launch the app
    """
    def __init__(self):
        pass

    def execute(self, args):
        # ----------------------- options input files -----------------------
        sFile = args.samples_file
        # ----------------------- options output prefix -----------------------
        output_prefix = args.output_base
        uncompressed = args.uncompressed
        output_unidentified = args.unidentified
        # ----------------------- other options ------------
        debug = args.debug
        verbose = not args.verbose
        batchsize = args.batchsize

        from dbcAmplicons import splitreadsApp
        app = splitreadsApp()

        if profile:
            import cProfile
            cProfile.runctx('app.start(args.fastq_file1, args.fastq_file2, output_prefix, sFile, batchsize, uncompressed, output_unidentified, verbose, debug)', globals(), locals())
            return 255
        else:
            return app.start(args.fastq_file1, args.fastq_file2, output_prefix, sFile, batchsize, uncompressed, output_unidentified, verbose, debug)


#####################################################################################
# join reads using flash, path through application
def joinFun(args, verbose):
    from dbcAmplicons import parse_flash
#    print args
    p = Popen(args, stdout=PIPE, stderr=STDOUT, close_fds=False)
    pf = parse_flash(p.stdout, verbose)
    return pf


def joinParser(subparsers):
    """
    joinParser parser parameters
    """
    #
    # Parse options
    #
    preprocess_parser = subparsers.add_parser('join', help='join reads using flash2')
    preprocess_parser.add_argument('-O', '--output_path', help='path for output files [default: %(default)s]',
                        action='store', type=str, dest='output_base', metavar='PREFIX', default="joined")
    preprocess_parser.add_argument('-u', '--uncompressed', help='leave output files uncompressed [default: %(default)s]',
                        action='store_true', dest='uncompressed', default=False)
    preprocess_parser.add_argument('-x', '--max-mismatch-density', help=' Maximum allowed ratio between the number of \
                          mismatched base pairs and the overlap length. \
                          Two reads will not be combined with a given overlap \
                          if that overlap results in a mismatched base density \
                          higher than this value.  Note: Any occurrence of an \
                          "N" in either read is ignored and not counted \
                          towards the mismatches or overlap length. [default:%(default)s]', type=float, dest='max_mixmatch_density', metavar='NUM',
                          default=0.25)
    preprocess_parser.add_argument('-t', '--threads', metavar='NTHREADS', help='Set the number of worker threads. [default: %(default)s]',
                        type=int, dest='threads', default=1)
#    preprocess_parser.add_argument('-p', '--flash2_path', help='path to the application flash2 [default: %(default)s]',
#                        action='store', type=str, dest='flash2_path',metavar='path', default='flash2', required=False)
    preprocess_parser.add_argument('-v', '--verbose', help='verbose output [default: %(default)s]',
                        action='store_true', dest='verbose', default=True)
    preprocess_parser.add_argument('-1', metavar="read1", dest='fastq_file1', help='read1 of an amplicon fastq (or fastq.gz) two file set',
                        action='store', type=str, required=True)
    preprocess_parser.add_argument('-2', metavar="read2", dest='fastq_file2', help='read2 of an amplicon fastq (or fastq.gz)  two file set',
                        action='store', type=str, required=False)
    return preprocess_parser


class joinCMD:
    """
    validate joinApp parser parameters and launch the app
    """
    def __init__(self):
        pass

    def execute(self, args):
        # ----------------------- options output prefix -----------------------
        output_prefix = args.output_base

        from dbcAmplicons import misc
        misc.make_sure_path_exists(os.path.dirname(output_prefix))
        if args.uncompressed:
            compress = ""
        else:
            compress = '-z'
        if not os.path.isfile(args.fastq_file1):
            sys.stderr.write("File: %s not found" % args.fastq_file1)
            sys.exit()
        fastq_file1 = os.path.realpath(args.fastq_file1)

        if args.fastq_file2 is None:
            fastq_file2 = misc.infer_read_file_name(fastq_file1, "2")
        elif not os.path.isfile(args.fastq_file2):
            sys.stderr.write("File: %s not found" % args.fastq_file2)
            sys.exit()
        else:
            fastq_file2 = args.fastq_file2

        flash_path = spawn.find_executable("flash2")
        if flash_path is None:
            flash2_download = "https://github.com/dstreett/FLASH2"
            sys.stderr.write("flash2 not found, please download and install from: %s\n" % flash2_download)
            sys.exit()

        # System call, try adding Popen and CString to capture output
        call_string = [flash_path, "--max-overlap", str(600), "--allow-outies", "-t", str(args.threads), "-x", str(args.max_mixmatch_density), "-o", output_prefix, compress, fastq_file1, fastq_file2]
        if profile:
            import cProfile
            cProfile.runctx('joinFun(call_string, args.verbose)', globals(), locals())
            return 255
        else:
            return joinFun(call_string, args.verbose)


#####################################################################################
# Classify reads using rdp
def classifyParser(subparsers):
    """
    classifyParser parser parameters
    """
    #
    # Parse options
    #
    preprocess_parser = subparsers.add_parser('classify', help='classify reads using RDP generating a fixrank formated file')
    preprocess_parser.add_argument('-b', '--batchsize', help='batch size to process reads in [default: %(default)s]',
                        type=int, dest='batchsize', default=100000)
    preprocess_parser.add_argument('-q', '--minQ', help="trim 3' end of sequences to minQ (paired-end reads only) [default: %(default)s]",
                        type=int, dest='minQ', default=None),
    preprocess_parser.add_argument('-l', '--minL', help='if minQ is not None, only keep reads that are at least minL length (paired-end reads only) [default: %(default)s]',
                        type=int, dest='minL', default=0),
    preprocess_parser.add_argument('-p', '--processors', help='number of processors to use, [default: %(default)s]',
                        type=int, dest='procs', default=1)
    preprocess_parser.add_argument('--rdpPath', metavar='PATH', dest='rdpPath', help='path to the RDP classifier',
                        action='store', type=str, default='classify.jar', required=True)
    preprocess_parser.add_argument('-g', '--gene', metavar='<arg>', dest='gene', help='16srrna, fungallsu, fungalits_warcup, or fungalits_unite [default: %(default)s]',
                        action='store', type=str, default='16srrna', required=False)
    preprocess_parser.add_argument('-t', '--train', help='RDP property file containing the mapping of the training files for a custom RDP training set, if not using the default.',
                        action='store', dest="train", default=None)
    preprocess_parser.add_argument('-O', '--output_path', help='path for output files [default: %(default)s]',
                        action='store', type=str, dest='output_base', metavar='outputPrefix', default='classify')
    preprocess_parser.add_argument('-1', metavar="read1", dest='fastq_file1', help='read1 of an amplicon fastq two file set',
                        action='store', type=str, default=None, required=False, nargs='+')
    preprocess_parser.add_argument('-2', metavar="read2", dest='fastq_file2', help='read2 of an amplicon fastq two file set',
                        action='store', type=str, default=None, required=False, nargs='+')
    preprocess_parser.add_argument('-U', metavar="single", dest='fastq_file3', help='single-end amplicon, typically from joined paired reads',
                        action='store', type=str, default=None, required=False, nargs='+')
    preprocess_parser.add_argument('-v', '--silent', help='silences verbose output [default: %(default)s]',
                        action='store_true', dest='verbose', default=False)
    preprocess_parser.add_argument('--debug', help='show traceback on error',
                        action='store_true', dest="debug", default=False)
    return preprocess_parser


class classifyCMD:
    """
    validate classifyApp parser parameters and launch the app
    """
    def __init__(self):
        pass

    def execute(self, args):
        # ----------------------- options output prefix -----------------------
        output_prefix = args.output_base
        # ----------------------- other options ------------
        debug = args.debug
        verbose = not args.verbose
        batchsize = args.batchsize
        procs = args.procs
        rdpPath = args.rdpPath

        if os.path.isfile(rdpPath) is not True:
            rdp_download = "https://github.com/rdpstaff/RDPTools"
            sys.stderr.write("RDP classifier.jar not found, please download and install from: %s\n" % rdp_download)
            sys.exit()

        rdp_call = ['java', '-Xmx2048M', '-Xms256M', '-XX:+UseParallelGC', '-XX:ParallelGCThreads=2', '-jar', rdpPath]
        if verbose:
            sys.stderr.write("Testing the RDP Classifier\n")
        try:
            with open(os.devnull, 'w') as devnull:
                check_call(rdp_call, stderr=devnull, stdout=devnull)
        except CalledProcessError:
            rdp_download = "https://github.com/rdpstaff/RDPTools"
            sys.stderr.write("RDP classifier.jar not found, please download and install from: %s\n" % rdp_download)
            sys.exit()

        if (procs > cpu_count()):
            sys.stderr.write("The number of processors specified [%s] is greater than the number available [%s], exiting application\n" % (str(procs), str(cpu_count())))
            sys.exit()
        if (args.train is None and args.gene != '16srrna' and args.gene != 'fungallsu' and args.gene != "fungalits_warcup" and args.gene != "fungalits_unite"):
            sys.stderr.write("parameter -g (--gene) must be one of 16srrna or fungallsu or fungalits_warcup or fungalits_unite\n")
            sys.exit()
        from dbcAmplicons import classifyApp
        app = classifyApp()

        if profile:
            import cProfile
            cProfile.runctx('app.start(args.fastq_file1, args.fastq_file2, args.fastq_file3, output_prefix, rdpPath, args.gene, args.train, batchsize, args.minQ, args.minL, procs, verbose, debug)', globals(), locals())
            return 255
        else:
            return app.start(args.fastq_file1, args.fastq_file2, args.fastq_file3, output_prefix, rdpPath, args.gene, args.train, batchsize, args.minQ, args.minL, procs, verbose, debug)


def abundanceParser(subparsers):
    """
    Compute an abundance table from classified reads in fixrank format
    abundanceParser parser parameters
    """
    #
    # Parse options
    #
    preprocess_parser = subparsers.add_parser('abundance', help='Generate an abundance table from a fixrank formated file')
    preprocess_parser.add_argument('-r', '--rank', help='taxonomic rank to build table from, allowable values are (domain, phylum, class, order, family, genus, and species{if performed}, [default: %(default)s]',
                        action='store', type=str, dest='rank', metavar='<arg>', default='genus', required=False, choices=['domain', 'phylum', 'class', 'order', 'family', 'genus', 'species'])
    preprocess_parser.add_argument('-t', '--threshold', help='Threshold bootstrap value to use for assignment, first taxon level greater than threshold',
                        type=float, dest='threshold', metavar="VALUE", default=0.5, required=False)
    preprocess_parser.add_argument('-m', '--minsize', help='Min size of amplicon to consider',
                        type=int, dest='minsize', metavar="VALUE", default=None, required=False)
    preprocess_parser.add_argument('-M', '--maxsize', help='Max size of amplicon to consider',
                        type=int, dest='maxsize', metavar="VALUE", default=None, required=False)
    preprocess_parser.add_argument('-S', '--sample_metadata', help='file with sample metadata',
                        action='store', type=str, dest='samples_file', metavar='FILE', default=None, required=False)
    preprocess_parser.add_argument('-O', '--output_path', help='path for output files [default: %(default)s]',
                        action='store', type=str, dest='output_base', metavar='FILE_PREFIX', default='table')
    preprocess_parser.add_argument('-F', metavar="FILE", dest='fixrank_file', help='fixrank formated classification file generated by classify',
                        action='store', type=str, default=None, required=True, nargs='+')
    preprocess_parser.add_argument('-b', '--biom', help='output biom formatted file [default: %(default)s]',
                        action='store_true', dest='biom', default=False)
    preprocess_parser.add_argument('-v', '--silent', help='verbose output [default: %(default)s]',
                        action='store_true', dest='verbose', default=False)
    preprocess_parser.add_argument('--debug', help='show traceback on error',
                        action='store_true', dest="debug", default=False)
    return preprocess_parser


class abundanceCMD:
    """
    validate abundanceApp parser parameters and launch the app
    """
    def __init__(self):
        pass

    def execute(self, args):
        # ----------------------- options input files -----------------------
        sFile = args.samples_file
        # ----------------------- options output prefix -----------------------
        output_prefix = args.output_base
        # ----------------------- other options ------------
        debug = args.debug
        verbose = not args.verbose

        from dbcAmplicons import abundanceApp
        app = abundanceApp()

        if profile:
            import cProfile
            cProfile.runctx('app.start(args.fixrank_file, sFile, output_prefix, args.rank, args.threshold, args.minsize, args.maxsize, args.biom verbose, debug)', globals(), locals())
            return 255
        else:
            return app.start(args.fixrank_file, sFile, output_prefix, args.rank, args.threshold, args.minsize, args.maxsize, args.biom, verbose, debug)


#####################################################################################
#  Master parser arguments
def parseArgs():
    """
    generate main parser
    """
    parser = argparse.ArgumentParser(
        description='dbcAmplicons, a python package for preprocessing of massively multiplexed, dual barcoded Illumina Amplicons',
        epilog='For questions or comments, please contact Matt Settles <msettles@uidaho.edu>', add_help=True)
    parser.add_argument('--version', action='version', version="%(prog)s Version " + version_num)
    subparsers = parser.add_subparsers(help='commands', dest='command')

    validateParser(subparsers)
    preprocessParser(subparsers)
    # splitreadsParser(subparsers)
    joinParser(subparsers)
    classifyParser(subparsers)
    abundanceParser(subparsers)

    args = parser.parse_args()

    return args


def main():
    """
    main function
    """
    lib_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), '../')
    if lib_path not in sys.path:
        sys.path.insert(0, lib_path)

    validate = validateCMD()
    preprocess = preprocessCMD()
    # splitreads = splitreadsCMD()
    join = joinCMD()
    classify = classifyCMD()
    abundance = abundanceCMD()

    # commands = {'preprocess': preprocess, 'splitreads': splitreads, 'join': join, 'classify': classify, 'abundance': abundance}
    commands = {'validate': validate, 'preprocess': preprocess, 'join': join, 'classify': classify, 'abundance': abundance}

    args = parseArgs()

    commands[args.command].execute(args)

if __name__ == '__main__':
    main()
